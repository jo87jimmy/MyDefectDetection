import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from datetime import datetime
def train_mlp_from_csv(csv_path="depreciation_records.csv", output_path="depreciation_mlp.pth"):
    """
    è² è²¬å¾ CSV è³‡æ–™è¨“ç·´æŠ˜èˆŠåˆ†æç”¨çš„ MLP æ¨¡å‹ï¼Œä¸¦å„²å­˜ç‚º .pth æª”æ¡ˆ
    è¨“ç·´ä¸€å€‹ç°¡å–®çš„ MLP æ¨¡å‹ä¾†é æ¸¬æŠ˜èˆŠç­‰ç´šã€‚æ•´é«”æµç¨‹åŒ…å«ï¼š
    è³‡æ–™è®€å–èˆ‡è½‰æ›ï¼Œæ¨¡å‹å»ºç«‹èˆ‡è¨“ç·´ï¼Œæ¨¡å‹å„²å­˜èˆ‡æç¤º
    ç”¨æ–¼æŒçºŒæ›´æ–°æ¨¡å‹çš„å ´æ™¯ï¼Œä¾‹å¦‚æ¯æ–°å¢ N ç­†ç´€éŒ„å°± retrainã€‚
    todo:
    æ¨¡å‹è©•ä¼°(accuracyã€confusion matrix)
    early stopping æˆ– learning rate schedulerï¼Œå¤šå±¤æ¶æ§‹æˆ– dropout   
    """
    df = pd.read_csv(csv_path)  # å¾ CSV æª”æ¡ˆè®€å–æŠ˜èˆŠç´€éŒ„è³‡æ–™
    # ğŸ”¢ ç‰¹å¾µèˆ‡æ¨™ç±¤æº–å‚™
    X = torch.tensor(df[["defect_index", "avg_depth", "max_depth", "total_area"]].values, dtype=torch.float32)  # å–å‡ºå››å€‹æŒ‡æ¨™ä½œç‚ºè¼¸å…¥ç‰¹å¾µ
    y = torch.tensor(df["grade"].map({"A - æ­£å¸¸": 0, "B - è§€å¯Ÿä¸­": 1, "C - å»ºè­°ç¶­ä¿®": 2}).values, dtype=torch.long)  # å°‡ç­‰ç´šè½‰ç‚ºæ•¸å€¼æ¨™ç±¤
    # ğŸ“¦ å»ºç«‹è³‡æ–™é›†èˆ‡ DataLoader
    dataset = torch.utils.data.TensorDataset(X, y)  # å°‡ç‰¹å¾µèˆ‡æ¨™ç±¤æ‰“åŒ…æˆ PyTorch è³‡æ–™é›†
    loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)  # å»ºç«‹è³‡æ–™è¼‰å…¥å™¨ï¼Œæ‰¹æ¬¡å¤§å°ç‚º 32ï¼Œä¸¦æ‰“äº‚é †åº
    # ğŸ§  å»ºç«‹æ¨¡å‹èˆ‡è¨“ç·´å…ƒä»¶
    model = DepreciationMLP()  # å»ºç«‹ MLP æ¨¡å‹ï¼ˆä½¿ç”¨é è¨­æ¶æ§‹ï¼‰
    criterion = nn.CrossEntropyLoss()  # ä½¿ç”¨äº¤å‰ç†µä½œç‚ºåˆ†é¡æå¤±å‡½å¼
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # ä½¿ç”¨ Adam å„ªåŒ–å™¨ï¼Œå­¸ç¿’ç‡ç‚º 0.01
    # ğŸ” æ¨¡å‹è¨“ç·´è¿´åœˆ
    for epoch in range(50):  # è¨“ç·´ 50 å€‹ epoch
        for batch_x, batch_y in loader:  # éæ­·æ¯å€‹æ‰¹æ¬¡
            optimizer.zero_grad()  # æ¸…é™¤å‰ä¸€æ¬¡çš„æ¢¯åº¦
            logits = model(batch_x)  # å‰å‘å‚³æ’­ï¼Œå–å¾—é æ¸¬çµæœ
            loss = criterion(logits, batch_y)  # è¨ˆç®—æå¤±
            loss.backward()  # åå‘å‚³æ’­
            optimizer.step()  # æ›´æ–°æ¨¡å‹åƒæ•¸
    torch.save(model, output_path)  # å„²å­˜è¨“ç·´å®Œæˆçš„æ¨¡å‹è‡³æŒ‡å®šè·¯å¾‘
    print(f"âœ… æ¨¡å‹å·²è¨“ç·´ä¸¦å„²å­˜è‡³ {output_path}")  # é¡¯ç¤ºè¨“ç·´å®Œæˆè¨Šæ¯

def compute_depreciation_metrics(defects):
    """
    ğŸ“Œ ç”¨é€”ï¼šæ ¹æ“šç¼ºé™·æ¸…å–®è¨ˆç®—æŠ˜èˆŠåˆ†æçš„æ ¸å¿ƒæŒ‡æ¨™(defect_index)ã€‚
    æ¯å€‹ç¼ºé™·çš„å½±éŸ¿åŠ›ä»¥ã€Œé¢ç© Ã— æ·±åº¦ã€è¡¨ç¤ºï¼Œä¸¦çµ±è¨ˆæ•´é«”ç¼ºé™·æ•¸é‡ã€å¹³å‡æ·±åº¦ã€æœ€å¤§æ·±åº¦èˆ‡ç¸½é¢ç©ã€‚
    ğŸ”¢ å›å‚³å…§å®¹ï¼š
    - defect_indexï¼šæŠ˜èˆŠæŒ‡æ•¸ï¼ˆé¢ç© Ã— æ·±åº¦ çš„åŠ ç¸½ï¼‰
    - defect_countï¼šç¼ºé™·æ•¸é‡
    - avg_depthï¼šå¹³å‡æ·±åº¦
    - max_depthï¼šæœ€å¤§æ·±åº¦
    - total_areaï¼šæ‰€æœ‰ç¼ºé™·çš„ç¸½é¢ç©
    """
    if not defects:
        return {
            "defect_index": 0,
            "defect_count": 0,
            "avg_depth": 0,
            "max_depth": 0,
            "total_area": 0
        }

    defect_index = sum([d['area'] * d['depth'] for d in defects])
    avg_depth = np.mean([d['depth'] for d in defects])
    max_depth = np.max([d['depth'] for d in defects])
    total_area = sum([d['area'] for d in defects])
    return {
        "defect_index": defect_index,
        "defect_count": len(defects),
        "avg_depth": avg_depth,
        "max_depth": max_depth,
        "total_area": total_area
    }

def classify_depreciation(defect_index):
    """
    ğŸ“Œ ç”¨é€”ï¼šæ ¹æ“šæŠ˜èˆŠæŒ‡æ•¸ï¼ˆdefect_indexï¼‰é€²è¡Œåˆ†ç´šåˆ¤æ–·ï¼Œå”åŠ©ä½¿ç”¨è€…å¿«é€Ÿäº†è§£ç‰©ä»¶ç›®å‰çš„å¥åº·ç‹€æ…‹ã€‚
    ğŸ“Š åˆ†ç´šé‚è¼¯ï¼š
    - Aï¼šæ­£å¸¸ï¼ˆdefect_index < 50ï¼‰
    - Bï¼šè§€å¯Ÿä¸­ï¼ˆ50 â‰¤ defect_index < 150ï¼‰
    - Cï¼šå»ºè­°ç¶­ä¿®ï¼ˆdefect_index â‰¥ 150ï¼‰
    ğŸ” å›å‚³ï¼š
    å°æ‡‰çš„æŠ˜èˆŠç­‰ç´šå­—ä¸²ï¼ˆå«å»ºè­°ï¼‰
    """
    if defect_index < 50:
        return "A - æ­£å¸¸"
    elif defect_index < 150:
        return "B - è§€å¯Ÿä¸­"
    else:
        return "C - å»ºè­°ç¶­ä¿®"

def generate_depreciation_record(defects,mlp_model=None):
    """
    ğŸ“Œ ç”¨é€”ï¼šæ•´åˆæŠ˜èˆŠåˆ†ææµç¨‹ï¼Œç”Ÿæˆä¸€ç­†å®Œæ•´çš„ç´€éŒ„ã€‚
    åŒ…å«åˆ†ææ™‚é–“ã€æŠ˜èˆŠç­‰ç´šã€å„é …æŒ‡æ¨™èˆ‡åŸå§‹ç¼ºé™·æ¸…å–®ï¼Œæ–¹ä¾¿å„²å­˜ã€è¿½è¹¤èˆ‡å¯è¦–åŒ–ã€‚
    ğŸ§© çµ„æˆï¼š
    - timestampï¼šåˆ†ææ™‚é–“ï¼ˆæ ¼å¼ï¼šYYYY-MM-DD HH:MMï¼‰
    - gradeï¼šæŠ˜èˆŠç­‰ç´šï¼ˆç”± classify_depreciation åˆ¤æ–·ï¼‰
    - defect_index / defect_count / avg_depth / max_depth / total_areaï¼šç”± compute_depreciation_metrics è¨ˆç®—
    - defectsï¼šåŸå§‹ç¼ºé™·æ¸…å–®ï¼ˆå«é¢ç©ã€æ·±åº¦ã€ä½ç½®ç­‰ï¼‰
    ğŸ” å›å‚³ï¼š
    ä¸€å€‹ dict çµæ§‹çš„æŠ˜èˆŠåˆ†æç´€éŒ„
    """
    metrics = compute_depreciation_metrics(defects)
    if mlp_model: #ä½¿ç”¨ MLP æ¨¡å‹æ ¹æ“šç¼ºé™·æŒ‡æ¨™é æ¸¬æŠ˜èˆŠç­‰ç´šã€‚
        grade, confidence = classify_depreciation_mlp(metrics, mlp_model)
    else:       #ä½¿ç”¨ç°¡å–®çš„é–¾å€¼åˆ†é¡
        grade = classify_depreciation(metrics["defect_index"])
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
    return {
        "timestamp": timestamp,
        "grade": grade,
        "confidence": confidence if mlp_model else "N/A",
        **metrics,
        "defects": defects
    }

import torch.nn as nn
class DepreciationMLP(nn.Module):
    """ æŠ˜èˆŠåˆ†æç”¨çš„å¤šå±¤æ„ŸçŸ¥å™¨(MLP)æ¨¡å‹
    Linear 1 -
    æ¥æ”¶æŠ˜èˆŠæŒ‡æ¨™: defect_indexã€avg_depthã€max_depthã€total_area å››å€‹è¼¸å…¥ç‰¹å¾µï¼Œ
    é æ¸¬æŠ˜èˆŠç­‰ç´š(Aã€Bã€C ä¸‰é¡ï¼‰ã€‚
    è¼¸å…¥ç¶­åº¦:4(defect_indexã€avg_depthã€max_depthã€total_area)
    éš±è—å±¤ç¶­åº¦:16
    æ¿€æ´»å‡½æ•¸:ReLU éç·šæ€§è½‰æ›
    Linear 2 -
    è¼¸å‡ºç¶­åº¦:3(å°æ‡‰ä¸‰å€‹æŠ˜èˆŠç­‰ç´šé¡åˆ¥ A/B/C)
    ğŸ” å‰å‘å‚³æ’­æµç¨‹:
    è¼¸å…¥ â†’ ç·šæ€§å±¤1 â†’ ReLU â†’ ç·šæ€§å±¤2 â†’ è¼¸å‡º logits
    """
    def __init__(self, input_dim=4, hidden_dim=16, output_dim=3):
        super().__init__()# åˆå§‹åŒ– nn.Module çˆ¶é¡åˆ¥
        # ğŸ§  å®šç¾© MLP æ¶æ§‹ï¼šè¼¸å…¥å±¤ â†’ éš±è—å±¤ â†’ è¼¸å‡ºå±¤
        self.model = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),# ç·šæ€§å±¤ï¼šè¼¸å…¥ç¶­åº¦ â†’ éš±è—å±¤ç¶­åº¦
            nn.ReLU(),# å•Ÿç”¨å‡½æ•¸ï¼šReLU éç·šæ€§è½‰æ›
            nn.Linear(hidden_dim, output_dim)# ç·šæ€§å±¤ï¼šéš±è—å±¤ â†’ è¼¸å‡ºé¡åˆ¥æ•¸
        )
    def forward(self, x):
        return self.model(x)# å‰å‘å‚³æ’­ï¼šå°‡è¼¸å…¥ x å‚³å…¥æ¨¡å‹ä¸¦å›å‚³è¼¸å‡º

def classify_depreciation_mlp(metrics, mlp_model):
    """
    ä½¿ç”¨ MLP æ¨¡å‹æ ¹æ“šç¼ºé™·æŒ‡æ¨™é æ¸¬æŠ˜èˆŠç­‰ç´šï¼Œä¸¦å›å‚³ä¿¡å¿ƒåˆ†æ•¸ã€‚
    ğŸ”¢ è¼¸å…¥ï¼šmetrics dictï¼ˆåŒ…å« defect_indexã€avg_depthã€max_depthã€total_areaï¼‰
    ğŸ” å›å‚³ï¼štuple â†’ (æŠ˜èˆŠç­‰ç´šå­—ä¸², ä¿¡å¿ƒåˆ†æ•¸)
    """
    # ğŸ§® å°‡æŒ‡æ¨™è½‰ç‚ºå¼µé‡ä¸¦åŠ ä¸Š batch ç¶­åº¦
    input_tensor = torch.tensor([
        metrics["defect_index"],
        metrics["avg_depth"],
        metrics["max_depth"],
        metrics["total_area"]
    ], dtype=torch.float32).unsqueeze(0)

    # ğŸš« æ¨è«–æ¨¡å¼ï¼ˆåœç”¨æ¢¯åº¦ï¼‰
    with torch.no_grad():
        logits = mlp_model(input_tensor)  # å‰å‘å‚³æ’­,logits æ˜¯ MLP æ¨¡å‹çš„åŸå§‹è¼¸å‡ºï¼ˆæœªç¶“æ¨™æº–åŒ–ï¼‰ï¼Œé€šå¸¸æ˜¯æ¯å€‹é¡åˆ¥çš„åˆ†æ•¸
        probs = torch.softmax(logits, dim=1)  # è¨ˆç®— softmax æ©Ÿç‡åˆ†å¸ƒï¼Œsoftmax å°‡ logits è½‰æ›ç‚ºæ©Ÿç‡åˆ†å¸ƒï¼Œä½¿æ‰€æœ‰é¡åˆ¥çš„æ©Ÿç‡åŠ ç¸½ç‚º 1ã€‚
        #EX:logits = [1.2, 3.5, 0.8] (æ‰€æœ‰é¡åˆ¥çš„æ©Ÿç‡åŠ ç¸½ç‚º1æ™‚)-> probs = [0.12, 0.82, 0.06]
        pred = torch.argmax(probs, dim=1).item()  # å–å¾—é æ¸¬é¡åˆ¥ç´¢å¼•ï¼Œpred æ˜¯æœ€å¤§æ©Ÿç‡çš„é¡åˆ¥ç´¢å¼•ï¼ˆå³æ¨¡å‹é æ¸¬çš„åˆ†é¡ï¼‰ã€‚
        confidence = probs[0, pred].item()  # å–å¾—è©²é¡åˆ¥çš„ä¿¡å¿ƒåˆ†æ•¸ï¼Œæ˜¯è©²é¡åˆ¥çš„æ©Ÿç‡å€¼ï¼Œä»£è¡¨æ¨¡å‹å°é€™å€‹é æ¸¬çš„ä¿¡å¿ƒã€‚

    # ğŸ“¤ å›å‚³ç­‰ç´šèˆ‡ä¿¡å¿ƒåˆ†æ•¸
    label = ["A - æ­£å¸¸", "B - è§€å¯Ÿä¸­", "C - å»ºè­°ç¶­ä¿®"]
    # ä¿¡å¿ƒåˆ†æ•¸(confidence)çš„ç”¨é€”ï¼š
    # å ±è¡¨å‘ˆç¾ï¼šè®“ä½¿ç”¨è€…çŸ¥é“é æ¸¬æ˜¯å¦å¯é 
    # è­¦ç¤ºæ©Ÿåˆ¶ï¼šè‹¥ä¿¡å¿ƒä½æ–¼æŸé–€æª»ï¼ˆä¾‹å¦‚ 0.6ï¼‰ï¼Œå¯æ¨™ç¤ºç‚ºã€Œä¸ç¢ºå®šã€
    # æ¨¡å‹è©•ä¼°ï¼šå¯ç”¨æ–¼ ROC æ›²ç·šã€Precision-Recall åˆ†æ
    # æ±ºç­–æ”¯æ´ï¼šé«˜ä¿¡å¿ƒå¯è‡ªå‹•é€šéï¼Œä½ä¿¡å¿ƒå¯è½‰äººå·¥è¤‡æ ¸
    return label[pred], confidence
